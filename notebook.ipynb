{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8808337",
   "metadata": {},
   "source": [
    "# Запрос №1\n",
    "Напишите запрос, выбирающий информацию об имени и фамилии \n",
    "сотрудника (таблица employees), а также о названии отдела, в котором он \n",
    "работает (таблица departments). При этом выберите только сотрудников\n",
    "отдела IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d96ab0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+--------------------+\n",
      "|first_name|last_name|salary|job_title           |\n",
      "+----------+---------+------+--------------------+\n",
      "|Sundita   |Kumar    |6100.0|Sales Representative|\n",
      "|Amit      |Banda    |6200.0|Sales Representative|\n",
      "|Charles   |Johnson  |6200.0|Sales Representative|\n",
      "|Sundar    |Ande     |6400.0|Sales Representative|\n",
      "|David     |Lee      |6800.0|Sales Representative|\n",
      "|Kimberely |Grant    |7000.0|Sales Representative|\n",
      "|Oliver    |Tuvault  |7000.0|Sales Representative|\n",
      "|Sarath    |Sewall   |7000.0|Sales Representative|\n",
      "|Mattea    |Marvins  |7200.0|Sales Representative|\n",
      "|Elizabeth |Bates    |7300.0|Sales Representative|\n",
      "|William   |Smith    |7400.0|Sales Representative|\n",
      "+----------+---------+------+--------------------+\n",
      "only showing top 11 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "\n",
    "jobDf = spark.read.parquet('data/jobs.parquet')\n",
    "empDf = spark.read.parquet('data/employees.parquet')\n",
    "df = empDf.join(jobDf, empDf.job_id == jobDf.job_id, \"inner\") \\\n",
    "    .filter(\"job_title='Sales Representative'\").sort(\"salary\", \"first_name\")\n",
    "df.select(\"first_name\", \"last_name\", \"salary\", \"job_title\").show(11, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7115faa",
   "metadata": {},
   "source": [
    "## Запрос №2\n",
    "Напишите запрос, выбирающий информацию об имени и фамилии \n",
    "сотрудника, названии отдела, в котором он работает, и стране, в которой он \n",
    "размещён. При этом запрос должен выбирать только информацию о\n",
    "сотрудниках из соединенных штатов, работающих в отделах «Shipping» и \n",
    "«Finance»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a34bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------------+------------------------+\n",
      "|first_name |last_name|department_name|country_name            |\n",
      "+-----------+---------+---------------+------------------------+\n",
      "|Nancy      |Greenberg|Finance        |United States of America|\n",
      "|Daniel     |Faviet   |Finance        |United States of America|\n",
      "|John       |Chen     |Finance        |United States of America|\n",
      "|Ismael     |Sciarra  |Finance        |United States of America|\n",
      "|Jose Manuel|Urman    |Finance        |United States of America|\n",
      "|Luis       |Popp     |Finance        |United States of America|\n",
      "|Matthew    |Weiss    |Shipping       |United States of America|\n",
      "|Adam       |Fripp    |Shipping       |United States of America|\n",
      "|Payam      |Kaufling |Shipping       |United States of America|\n",
      "|Shanta     |Vollman  |Shipping       |United States of America|\n",
      "|Kevin      |Mourgos  |Shipping       |United States of America|\n",
      "+-----------+---------+---------------+------------------------+\n",
      "only showing top 11 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "\n",
    "depDf = spark.read.parquet('data/department.parquet')\n",
    "locDf = spark.read.parquet('data/locations.parquet')\n",
    "cntryDf = spark.read.parquet('data/countries.parquet')\n",
    "empDf = spark.read.parquet('data/employees.parquet')\n",
    "\n",
    "df = empDf.join(depDf, empDf.department_id == depDf.department_id, \"inner\")\n",
    "df = df.join(locDf, df.location_id == locDf.location_id, \"inner\")\n",
    "df = df.join(cntryDf, df.country_id == cntryDf.country_id, \"inner\")\n",
    "df.filter(\"country_name='United States of America'\") \\\n",
    "    .filter((df.department_name == 'Shipping') | (df.department_name == 'Finance')) \\\n",
    "    .select(\"first_name\", \"last_name\", \"department_name\", \"country_name\").show(11, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f924ed",
   "metadata": {},
   "source": [
    "## Запрос №3\n",
    "Напишите запрос, выбирающий информацию по всем служащим, \n",
    "нанятым раньше своих менеджеров. При этом выведите фамилии и даты \n",
    "найма самих служащих, а также фамилии и даты найма их менеджеров. \n",
    "Пример возможного результата выполнения запроса представлен в \n",
    "таблице ниже. Поля должны называться так же, как указано в примере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa06ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+----------+\n",
      "|Фамилия_Р|Дата_Р    |Фамилия_М|Дата_М    |\n",
      "+---------+----------+---------+----------+\n",
      "|De Haan  |13.01.2001|King     |17.06.2003|\n",
      "|Hunold   |03.01.2006|De Haan  |13.01.2001|\n",
      "|Greenberg|17.08.2002|Kochhar  |21.09.2005|\n",
      "|Faviet   |16.08.2002|Greenberg|17.08.2002|\n",
      "|Urman    |07.03.2006|Greenberg|17.08.2002|\n",
      "|Popp     |07.12.2007|Greenberg|17.08.2002|\n",
      "|Raphaely |07.12.2002|King     |17.06.2003|\n",
      "|Fripp    |10.04.2005|King     |17.06.2003|\n",
      "|Kaufling |01.05.2003|King     |17.06.2003|\n",
      "|Vollman  |10.10.2005|King     |17.06.2003|\n",
      "+---------+----------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "\n",
    "empDf = spark.read.parquet('data/employees.parquet')\n",
    "\n",
    "cmp = udf(lambda a, b: tuple(map(int, a.split('.'))) < tuple(map(int, b.split('.'))), BooleanType())\n",
    "\n",
    "df = empDf.withColumnRenamed(\"last_name\", \"Фамилия_Р\").withColumnRenamed(\"hire_date\", \"dt_w\")\n",
    "df2 = empDf.select(\"employee_id\", \"last_name\", \"hire_date\")\n",
    "df = df.join(df2, df.manager_id == df2.employee_id, \"inner\") \\\n",
    "    .where(cmp(col(\"dt_w\"), col(\"hire_date\"))).withColumnRenamed(\"last_name\", \"Фамилия_М\") \\\n",
    "    .withColumnRenamed(\"hire_date\", \"Дата_М\").withColumnRenamed(\"dt_w\", \"Дата_Р\")\n",
    "df.select(\"Фамилия_Р\", \"Дата_Р\", \"Фамилия_М\", \"Дата_М\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8824bc",
   "metadata": {},
   "source": [
    "## Запрос №4\n",
    "Напишите запрос, выбирающий информацию о фамилии, имени и \n",
    "окладе всех служащих, оклад которых выше среднего. Отсортируйте \n",
    "выходные данные в порядке увеличения окладов. Пример возможного \n",
    "результата выполнения запроса представлен в таблице ниже. Поля \n",
    "должны называться так же, как указано в примере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a2269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------+\n",
      "|Фамилия_Р|Имя      |Оклад |\n",
      "+---------+---------+------+\n",
      "|Mavris   |Susan    |6500.0|\n",
      "|Vollman  |Shanta   |6500.0|\n",
      "|Lee      |David    |6800.0|\n",
      "|Popp     |Luis     |6900.0|\n",
      "|Grant    |Kimberely|7000.0|\n",
      "|Sewall   |Sarath   |7000.0|\n",
      "|Tuvault  |Oliver   |7000.0|\n",
      "|Marvins  |Mattea   |7200.0|\n",
      "|Bates    |Elizabeth|7300.0|\n",
      "|Smith    |William  |7400.0|\n",
      "+---------+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "\n",
    "empDf = spark.read.parquet('data/employees.parquet')\n",
    "\n",
    "df = empDf.filter(empDf.salary > empDf.select(avg('salary')).collect()[0][0]).sort(\"salary\", 'last_name') \\\n",
    "    .withColumnRenamed(\"last_name\", \"Фамилия_Р\").withColumnRenamed(\"first_name\", \"Имя\").withColumnRenamed(\"salary\",\n",
    "                                                                                                          \"Оклад\")\n",
    "df.select(\"Фамилия_Р\", \"Имя\", \"Оклад\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f867c8",
   "metadata": {},
   "source": [
    "## Запрос №5\n",
    "Напишите запрос, выбирающий имена и фамилии сотрудников на \n",
    "основе информации из таблицы employees. Должны быть выбраны записи \n",
    "только для тех сотрудников, которые выполняют менеджерские функции \n",
    "(для которых их номер employee_id встречается в столбце manager_id той же \n",
    "таблицы). Решите эту задачу при помощи многострочного подзапроса. \n",
    "Пример возможного результата выполнения запроса представлен в \n",
    "таблице ниже. Поля должны называться так же, как указано в примере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d69907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|      Имя|  Фамилия|\n",
      "+---------+---------+\n",
      "|  Shelley|  Higgins|\n",
      "|  Michael|Hartstein|\n",
      "|    Eleni|  Zlotkey|\n",
      "|   Gerald|Cambrault|\n",
      "|  Alberto|Errazuriz|\n",
      "|    Karen| Partners|\n",
      "|     John|  Russell|\n",
      "|    Kevin|  Mourgos|\n",
      "|   Shanta|  Vollman|\n",
      "|    Payam| Kaufling|\n",
      "|     Adam|    Fripp|\n",
      "|  Matthew|    Weiss|\n",
      "|      Den| Raphaely|\n",
      "|    Nancy|Greenberg|\n",
      "|Alexander|   Hunold|\n",
      "|      Lex|  De Haan|\n",
      "|    Neena|  Kochhar|\n",
      "|   Steven|     King|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "\n",
    "empDf = spark.read.parquet('data/employees.parquet')\n",
    "managers = empDf.rdd.map(lambda x: x.manager_id).collect()\n",
    "df = empDf.where(col(\"employee_id\").isin(managers)) \\\n",
    "    .withColumnRenamed(\"first_name\", \"Имя\").withColumnRenamed(\"last_name\", \"Фамилия\")\n",
    "df.sort(df.employee_id.desc()).select(\"Имя\", \"Фамилия\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af29a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
